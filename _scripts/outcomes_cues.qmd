---
title: "Active Consent Cues"
author: "Stephanie Ward"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---

Packages

```{r, message=FALSE}
library(conflicted)  # detect and warn about conflicts

conflicts_prefer(dplyr::filter)

path_nids <- "_data/data_process"
path_ready <- "_data/data_ready"

library(tidyverse)   # data manipulation and visualization
library(janitor)     # data manipulation and visualization
library(glmmTMB)     # modeling
library(ordinal)     # modeling
library(psych)       # descriptives 
library(knitr)       # for report/table generation
```

Setup

```{r,  message = FALSE}
theme_set(theme_classic())
options(tibble.width = Inf)
options(tibble.print_max = Inf)
```

Read in data

```{r}
# dat <- readRDS(here::here("_data/data_process", "diary_cln_nid.rds"))
dat <- read_csv(here::here(path_ready, "ready_cues.csv"))

# b <- read_csv(here::here("_data", "baseline_cln_nid.csv"), show_col_types = FALSE)
b <- read_csv(here::here(path_nids,"baseline_nid.csv"), show_col_types = FALSE)
```

Merge baseline and daily diary data

```{r}
# 'nid' = unique participant identifier 
merged_data <- dat %>%
  left_join(b, by = "nid")

d_subset <- merged_data %>%
  filter(psb1 == 1)

d_subset %>%
  distinct(nid) %>%
  count(nid) %>%
  mutate(prop = n / sum(n))

d_sub_di <- merged_data %>%
  filter(psb_act != "Attempt")

d_sub_di %>%
  distinct(nid) %>%
  count(nid) %>%
  mutate(prop = n / sum(n))

merged_data %>%
  filter(psb1 == 3) %>%
  distinct(nid, gend) %>%
  count(gend) %>%
  mutate(prop = n / sum(n))

never_psb1 <- merged_data %>%
  group_by(nid) %>%
  summarise(ever_psb1 = any(psb1 == 1), .groups = "drop") %>%
  filter(!ever_psb1)

# count
n_never <- nrow(never_psb1)

# proportion
prop_never <- n_never / n_distinct(d$nid)

# results
list(
  n_never = n_never,
  prop_never = prop_never
)

merged_data %>%
  group_by(nid) %>%
  summarise(ever_psb1 = any(psb1 == 1), .groups = "drop") %>%
  count(ever_psb1) %>%
  mutate(prop = n / sum(n))

psb_check <- merged_data %>%
  group_by(nid) %>%
  summarise(
    ever_psb1 = any(psb1 == 1),     # did they ever report psb1 == 1?
    ever_psb_di1 = any(psb_act == "Attempt") # did they ever report psb_di == 1?
  ) %>%
  filter(ever_psb1, !ever_psb_di1)  # keep only those with psb1 == 1 but never psb_di == 1

nrow(psb_check)  # number of such participants

merged_data %>% select(psb_di, psb_act) %>% map(tabyl)
```

### Demographics 
```{r}
gender_breakdown <- d_subset %>%
  filter(psb_di == 1) %>%
  distinct(nid, gend) %>%
  count(gend) %>%
  mutate(prop = n / sum(n))

gender_breakdown

age_breakdown <- d_subset %>%
  filter(psb_di == 1) %>%
  distinct(nid, age) %>%
  count(age) %>%
  mutate(prop = n / sum(n))

age_breakdown

grade_breakdown <- d_subset %>%
  filter(psb_di == 1) %>%
  distinct(nid, sch_yr) %>%
  count(sch_yr) %>%
  mutate(prop = n / sum(n))

grade_breakdown 

ori_breakdown <- d_subset %>%
  filter(psb_di == 1) %>%
  distinct(nid, sx_ori) %>%
  count(sx_ori) %>%
  mutate(prop = n / sum(n))

ori_breakdown

rela_breakdown <- d_subset %>%
  filter(psb_di == 1) %>%
  distinct(nid, rela) %>%
  count(rela) %>%
  mutate(prop = n / sum(n))

rela_breakdown

acts_breakdown <- d_subset %>%
  distinct(nid, psb_act) %>%
  count(psb_act) %>%
  mutate(prop = n / sum(n))

acts_breakdown
```


### External consent cues

#### Sliding-scale (VAS) responses

Forced-response items with default set to 0, requiring manual inspection
for straight-lining and non-random "missingness"

```{r,eval=FALSE}
merged_data %>% 
  filter(psb1 == 1, 
         ver_pc == 0, enon_pc > 0, inon_pc > 0) %>%
  select(nid) %>% glimpse()

merged_data %>% 
  filter(psb1 == 1,
         ver_pc > 0, enon_pc == 0, inon_pc == 0) %>%
  select(nid) %>% glimpse()

merged_data %>% 
  filter(psb1 == 1,
         ver_pc == 0, enon_pc > 0, inon_pc == 0) %>%
  select(nid) %>% glimpse()
```

```{r}
# view subject IDs w/ at least 1 encounter for which they endorsed 
# "Not at all" across all external and internal cues. 
merged_data %>% 
  filter(psb1 == 1, 
         ver_pc == 0, enon_pc == 0, inon_pc == 0,
         con_pf == 0, aro_pf == 0, pls_pf == 0) %>%
  select(nid) %>% map(tabyl)

# Check how many sexual events included just "attempts" or kissing/touching
merged_data %>% select(psb_act) %>% map(tabyl)

# View subject IDs w/ at least 1 encounter involving penetration for which
# they endorsed "Not at all" across all external and internal cues
merged_data %>% 
  filter(psb1 == 1, psb_act == "Penetration", 
         ver_pc == 0, enon_pc == 0, inon_pc == 0,
         con_pf == 0, aro_pf == 0, pls_pf == 0) %>%
  select(nid) %>% map(tabyl)
```

##### Legit

```{r, eval=FALSE}
merged_data %>% # looks legit, response: R_0oexjZcflARrq9P
  filter(nid == 2351222, psb1 == 1) %>% view()

merged_data %>% # looks legit, response: R_1q4I2PR1MOtNOas
  filter(nid == 2460338, psb1 == 1, ) %>% view()

merged_data %>% # legit response: R_3NxHqUwX3ATt3o7 (co-occurring en-bloc AIB)
  filter(nid == 6191138, psb1 == 1) %>% view()

merged_data %>% # legit response: R_CmK5aMPfxuRuIed (endorsed victimization)
  filter(nid == 7109663, psb1 == 1, psb_act == "Penetration") %>% view()

merged_data %>% # legit response: R_1KqhJP8hN0eu2AT (bodily contact only)
  filter(nid == 3722889, psb1 == 1, ) %>% view()

merged_data %>% # legit response: R_1KqhJP8hN0eu2AT (bodily contact only)
  filter(nid == 5359974, psb1 == 1, ) %>% view()
```

##### Low-quality

```{r, eval=FALSE}
merged_data %>% # straightlining: R_4Pjqjwp0mwiiwsF (?)
  filter(nid == 8890545, psb1 == 1) %>% view()

merged_data %>% # straightlining: R_1rDt67OsSeVdJdD (?)
  filter(nid == 1948818, psb1 == 1) %>% view()

merged_data %>% # straightlining: R_1IiVp3zqi97TBIF or R_3fVPZSasG72CF7b (?)
  filter(nid == 9128298, psb1 == 1) %>% view()

merged_data %>% # 3 events, 1 penetrative - could be legit (?)  
  filter(nid == 8365590, psb1 == 1) %>% view()

merged_data %>% # incomplete response: R_4Pjqjwp0mwiiwsF 
  filter(nid == 8890545, psb1 == 1) %>% view() # review for flagged "duplicate"
# may have deleted corrected response from participant after they accidentally 
# endorsed PSB when they meant to report solo / online (porn consumption)
```

#### Verbal

`ver_pc`: Directly asked your partner or communicated verbally with your
partner about consent? Number of sexual events with non-missing ver_pc

```{r}
psych::describe(merged_data$ver_pc)

hist(d$ver_pc)
```

**Histogram for verbal cues during penetrative sexual events**\
involving at least one of the following behaviors:

-   Penetration with fingers = 3
-   Oral sex = 4
-   Vaginal sex = 5
-   Anal sex = 6

```{r}
merged_data %>%
  filter(psb1 == 1, psb_act == "Penetration") %>%
  pull(ver_pc) %>%
  hist(main = "Histogram of Verbal Consent (Penetration Only)",
       xlab = "Verbal Consent Score",
       col = "lightblue",
       breaks = 10)
```

Calculate proportion of all partnered sexual events in `merged_data`
where the participant reported verbal consent communication when any
value greater than 0 on `ver_pc` indicates some degree of verbal consent
communication (var is on a 0–10 scale where 0 = not at all).

```{r}
proportion_verbal <- merged_data %>%
  filter(!is.na(ver_pc)) %>%
  summarise(
    total_events = n(),
    verbal_events = sum(ver_pc > 0),
    proportion_verbal = verbal_events / total_events
  )

```

-   `total_events`: Number of sexual events with non-missing ver_pc
-   `verbal_events`: Number of those events where the participant used
    verbal consent
-   `proportion_verbal`: Proportion of events with verbal consent use

```{r}
verbal_by_person <- merged_data %>%
  filter(!is.na(ver_pc)) %>%
  group_by(nid) %>%
  summarise(used_verbal = any(ver_pc > 0)) %>%
  ungroup()

# Total number of participants with ≥1 partnered sexual event
total_participants <- nrow(verbal_by_person)

# Number who used verbal consent at least once
participants_with_verbal <- sum(verbal_by_person$used_verbal)

# Proportion
proportion_with_verbal <- participants_with_verbal / total_participants

proportion_with_verbal
```

**However**... if 0 = "not at all" and 10 = "very much", then a score of
1 might reflect minimal or ambiguous expression of the cue.

Higher values (e.g., \>3 or 4 ) may reflect clearer, more intentional
communication. The threshold for coding verbal communication positive
should reflect a meaningful presence of the behavior, not just
statistical non-zero noise.

Now looking at the rest of the descriptives...

#### Direct, Nonverbal

`enon_pc`: Used direct non-verbal signals to communicate with your
partner about consent for the sexual activity?

```{r}
psych::describe(merged_data$enon_pc)

hist(d$enon_pc)
```

**Histogram for direct nonverbal cues during penetrative sexual events**

```{r}
merged_data %>%
  filter(psb1 == 1, psb_act == "Penetration") %>%
  pull(enon_pc) %>%
  hist(main = "Histogram of Direct Nonverbal Cues (Penetration Only)",
       xlab = "Direct Nonverbal Consent Score",
       col = "lightblue",
       breaks = 10)
```

#### Indirect, Nonverbal

`inon_pc`: Used subtle signals to communicate with your partner about
consent for the sexual activity?

```{r}
psych::describe(merged_data$inon_pc)

hist(d$inon_pc)
```

**Histogram for direct nonverbal cues during penetrative sexual events**

```{r}
merged_data %>%
  filter(psb1 == 1, psb_act == "Penetration") %>%
  pull(inon_pc) %>%
  hist(main = "Histogram of Indirect Nonverbal Cues (Penetration Only)",
       xlab = "Indirect Nonverbal Consent Score",
       col = "lightblue",
       breaks = 10)
```

-   Most participants report moderate to high use (median = 7–8).
-   The distributions look left-skewed, meaning the bulk of responses
    are toward higher values.
-   Scores of 1 or 2 may not represent meaningful endorsement.

#### Nonverbal score
```{r}
psych::describe(merged_data$non_verb)

hist(merged_data$non_verb)

merged_data %>% select(non_verb) %>% map(tabyl)

merged_data %>%
  filter(psb1 == 1, psb_act == "Penetration") %>%
  pull(non_verb) %>%
  hist(main = "Histogram of Nonverbal Consent (Penetration Only)",
       xlab = "Nonverbal Composite Score",
       col = "lightblue",
       breaks = 10)
```


### Threshold options

\> 0 (any use)

-   Pros: Most inclusive; captures any endorsement.
-   Cons: May reflect trivial or ambiguous use (e.g., a "1" could be an
    accidental response or minimal signal).

≥ 3 or ≥ 4 (low-to-moderate use threshold)

-   Common in behavioral research using 0–10 or 0–100 VAS-type scales.
-   Reflects a minimum threshold of meaningful use, not just accidental
    or fleeting presence.
-   Matches the logic of Likert-style midpoints (e.g., 4 = “somewhat”, 5
    = “moderately”).

≥ median (data-driven threshold)

-   Pros: Empirically grounded
-   Cons: Not intuitive across datasets or audiences, and could vary by
    cue type

### Internal consistency

#### Pooled for active cues

Calculate pooled (overall) Cronbach’s alpha to get a sense of how these
three items behave across all observations, regardless of nesting.

```{r}
# create a character vector for the active consent cues
acc_vector <- c("ver_pc","enon_pc", "inon_pc")

psych::alpha(d[, acc_vector], check.keys = T, na.rm = TRUE)
```

**Interpretation**: Internal consistency for the three active consent
cue items was \< .6 (α = 0.569), suggesting insufficient empirical 
support for combining them into a composite active consent
communication score.

```{r}
round(cor(merged_data$ver_pc, merged_data$enon_pc, use = "pairwise.complete.obs"), 3)

round(cor(merged_data$ver_pc, merged_data$inon_pc, use = "pairwise.complete.obs"), 3)

GGally::ggpairs(merged_data %>% select(ver_pc, non_verb))

view(merged_data)

merged_data <- merged_data %>%
  rowwise() %>%  # calculate mean score
  mutate(non_verb = mean(c(enon_pc,inon_pc)))


```


#### Per-Person for active cues

Do these three items consistently co-occur within individuals across
events?

#### Pooled for nonverbal cues

```{r}
# create a character vector for the nonverbal consent cues
nvb_vector <- c("enon_pc", "inon_pc")

psych::alpha(d[, nvb_vector], check.keys = T, na.rm = TRUE)

round(cor(merged_data$enon_pc, merged_data$inon_pc, use = "pairwise.complete.obs"), 3)


```

The correlation between the `direct` and `indirect nonverbal` consent
cue items was *r* = .736, indicating a strong positive relationship that
suggests these items reflect a shared underlying construct. For
parsimony and theoretical clarity, these items could be averaged to
create a continuous composite score representing overall nonverbal
consent communication.

```{r}
baseline %>% select(gend) %>% map(tabyl)

```

#### Content from the study_template serving as placeholders for figures and equations:

Figures will be created in separate notebooks and embedded in the proposal.

{{< embed notebooks/fig1.qmd#fig-1 >}}

I will use quarto inline to display math equations. Quarto provides [details](https://quarto.org/docs/authoring/markdown-basics.html#equations) on the use of these equations.

For example $x$ and $y$ are two variables. And here is an important formula:

$$
p(x) = \frac{e^{-\lambda} \lambda^{x}}{x !}
$$

To add results that are not figures or tables, I will open the objects I saved from these analyses. See lm.qmd as an example. Generally, I will open csv files that contain tidied results. For example:

```{r,echo=FALSE,message=FALSE,warning=FALSE}
library(tidyverse)

coeffs <- read_csv(here::here("objects/coeff_table.csv"),
                   col_types = cols())
```

A significant effect was observed ($\beta$ = `r sprintf("%1.1f", coeffs |> filter(term == "speed") |> pull(estimate))`, t = `r sprintf("%1.2f", coeffs |> filter(term == "speed") |> pull(statistic))`, p = `r sprintf("%1.3f", coeffs |> filter(term == "speed") |> pull(p.value))`).


```{r}
#| label: table-1
#| tbl-cap: Table 1

kbl(mtcars[1:10, 1:5]) |>
  kable_styling(bootstrap_options = "striped", full_width = F, position = "float_right") |>
  kable_styling(fixed_thead = T) |>
  add_header_above(c(" " = 1, "Group 1" = 2, "Group 2" = 2, "Group 3" = 1))

```

```{r}
#| label: table-2
#| tbl-cap: Table 2

knitr::kable(mtcars[1:2, 1:2], table.attr = "class=\"striped\"",
  format = "html")

```
